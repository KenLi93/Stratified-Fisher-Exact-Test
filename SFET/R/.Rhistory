library(breakaway)
CB.hat <- se.CB.hat <- 1:n * 0
?chao_bunge
CB.hat <- se.CB.hat <- 1:n * 0
## generate OTU counts by multinomial distribution
for (i in 1:n){
X[i,] <- rmultinom(1, size = M[i], prob = pcell[i,])
}
head(X)
## generate OTU counts by multinomial distribution
for (i in 1:n){
X[i,] <- rmultinom(1, size = M[i], prob = alpha)
}
head(X)
i=1
mb.samp <- X[i,]
mb.samp
freq.tab <- apply(as.matrix(as.data.frame(table(mb.samp))), 2, as.numeric)
freq.tab
freq.tab <- freq.tab[freq.tab[,1] != 0, ] ## omit unobserved entries
freq.tab
if (freq.tab[1,1] != 1) freq.tab <- rbind(c(1,0), freq.tab)
rich <- chao_bunge(freq.tab, cutoff = 10, output = F, answers = T)
rich
## get chao_bunge estimates
for (i in 1:n){
mb.samp <- X[i,]
freq.tab <- apply(as.matrix(as.data.frame(table(mb.samp))), 2, as.numeric)
freq.tab <- freq.tab[freq.tab[,1] != 0, ] ## omit unobserved entries
if (freq.tab[1,1] != 1) freq.tab <- rbind(c(1,0), freq.tab)
rich <- chao_bunge(freq.tab, cutoff = 10, output = F, answers = T)
CB.hat[i] <- rich$est
se.CB.hat[i] <- rich$seest
}
CB.hat
se.CB.hat
## generate taxonomic tables
tax.tab <- rep(1:(p/5), each = 5)
tax.tab
## generate taxonomic tables
tax.tab <- sample(rep(1:(p/5), each = 5))
tax.tab
?betta
betta(CB.hat, se.CB.hat)
betta(CB.hat, se.CB.hat, X = rep(c(0,1), each = n/2))
X = rep(c(0,1), each = n/2)
dim(X)
X
X = cbind(1,c(0,1), rep(each = n/2))
X = cbind(1, rep(c(0,1),each = n/2)
)
X
betta(CB.hat, se.CB.hat, X = cbind(1, rep(c(0,1),each = n/2)))
betta.test <- betta(CB.hat, se.CB.hat, X = cbind(1, rep(c(0,1),each = n/2)))
betta.test.stat <- betta.test$table[2,1]/betta.test$table[2,2]
betta.test.stat
betta.est <- betta.test$table[2,1]
betta.est
tax.tab
## agglomerate
X1 <- matrix(0, nrow = n, ncol = p/5)
j=2
X[i, tax.tab == j]
i=1
tax.tab == j
X[i, tax.tab == j]
length(tax.tab)
ncol(X)
X
n <- 100
p <- 200
N <- 500
## generate OTU counts from a multinomial distribution
## initiate OTU table: rows: sample; columns: taxa
X <- matrix(0, nrow = n, ncol = p)
## cell probability for the multinomial distribution
alpha <- 1:p / sum(1:p)
## Reading depth
M <- round(runif(n, 9000, 11000))
## generate OTU counts by multinomial distribution
for (i in 1:n){
X[i,] <- rmultinom(1, size = M[i], prob = alpha)
}
## generate taxonomic tables
tax.tab <- sample(rep(1:(p/5), each = 5))
CB.hat <- se.CB.hat <- 1:n * 0
## get chao_bunge estimates
for (i in 1:n){
mb.samp <- X[i,]
freq.tab <- apply(as.matrix(as.data.frame(table(mb.samp))), 2, as.numeric)
freq.tab <- freq.tab[freq.tab[,1] != 0, ] ## omit unobserved entries
if (freq.tab[1,1] != 1) freq.tab <- rbind(c(1,0), freq.tab)
rich <- chao_bunge(freq.tab, cutoff = 10, output = F, answers = T)
CB.hat[i] <- rich$est
se.CB.hat[i] <- rich$seest
}
betta.test <- betta(CB.hat, se.CB.hat, cbind(1, rep(c(0,1),each = n/2)))
betta.test.stat <- betta.test$table[2,1]/betta.test$table[2,2]
betta.est <- betta.test$table[2,1]
## agglomerate
X1 <- matrix(0, nrow = n, ncol = p/5)
temp <- X[i, tax.tab == j]
temp
X1 <- matrix(0, nrow = n, ncol = p/5)
for(i in 1:n){
for (j in 1:(p/5)){
X1 <- sum(X[i, tax.tab == j])
}
}
X1
X1 <- matrix(0, nrow = n, ncol = p/5)
for(i in 1:n){
for (j in 1:(p/5)){
X1[i,j] <- sum(X[i, tax.tab == j])
}
}
X1
## generate taxonomic tables
tax.tab <- sample(rep(1:(p/4), each = 4))
## agglomerate
X1 <- matrix(0, nrow = n, ncol = p/5)
for(i in 1:n){
for (j in 1:(p/5)){
X1[i,j] <- sum(X[i, tax.tab == j])
}
}
head(X1)
X
## generate taxonomic tables
tax.tab <- sample(rep(1:(p/2), each = 2))
## agglomerate
X1 <- matrix(0, nrow = n, ncol = p/2)
for(i in 1:n){
for (j in 1:(p/5)){
X1[i,j] <- sum(X[i, tax.tab == j])
}
}
X1
X1 <- matrix(0, nrow = n, ncol = p/2)
for(i in 1:n){
for (j in 1:(p/2)){
X1[i,j] <- sum(X[i, tax.tab == j])
}
}
X1
## cell probability for the multinomial distribution
alpha <- c(rep(1,p*3/4), rep(20, p*1/4))
alpha <- alpha/sum(alpha)
alpha
## Reading depth
M <- round(runif(n, 4500, 5500))
## generate OTU counts by multinomial distribution
for (i in 1:n){
X[i,] <- rmultinom(1, size = M[i], prob = alpha)
}
## generate taxonomic tables
tax.tab <- sample(rep(1:(p/2), each = 2))
CB.hat <- se.CB.hat <- 1:n * 0
## get chao_bunge estimates
for (i in 1:n){
mb.samp <- X[i,]
freq.tab <- apply(as.matrix(as.data.frame(table(mb.samp))), 2, as.numeric)
freq.tab <- freq.tab[freq.tab[,1] != 0, ] ## omit unobserved entries
if (freq.tab[1,1] != 1) freq.tab <- rbind(c(1,0), freq.tab)
rich <- chao_bunge(freq.tab, cutoff = 10, output = F, answers = T)
CB.hat[i] <- rich$est
se.CB.hat[i] <- rich$seest
}
betta.test <- betta(CB.hat, se.CB.hat, cbind(1, rep(c(0,1),each = n/2)))
betta.test.stat <- betta.test$table[2,1]/betta.test$table[2,2]
betta.est <- betta.test$table[2,1]
betta.est
CB.hat
head(x)
X
## generate taxonomic tables
tax.tab <- sample(rep(1:(p/2), each = 2))
## agglomerate
X1 <- matrix(0, nrow = n, ncol = p/2)
for(i in 1:n){
for (j in 1:(p/2)){
X1[i,j] <- sum(X[i, tax.tab == j])
}
}
X1
## cell probability for the multinomial distribution
alpha <- c(rep(1,p*3/4), rep(40, p*1/4))
alpha <- alpha/sum(alpha)
## cell probability for the multinomial distribution
alpha <- c(rep(1,p*4/5), rep(40, p*1/5))
alpha <- alpha/sum(alpha)
## Reading depth
M <- round(runif(n, 4500, 5500))
## generate OTU counts by multinomial distribution
for (i in 1:n){
X[i,] <- rmultinom(1, size = M[i], prob = alpha)
}
## generate taxonomic tables
tax.tab <- sample(rep(1:(p/2), each = 2))
CB.hat <- se.CB.hat <- 1:n * 0
## get chao_bunge estimates
for (i in 1:n){
mb.samp <- X[i,]
freq.tab <- apply(as.matrix(as.data.frame(table(mb.samp))), 2, as.numeric)
freq.tab <- freq.tab[freq.tab[,1] != 0, ] ## omit unobserved entries
if (freq.tab[1,1] != 1) freq.tab <- rbind(c(1,0), freq.tab)
rich <- chao_bunge(freq.tab, cutoff = 10, output = F, answers = T)
CB.hat[i] <- rich$est
se.CB.hat[i] <- rich$seest
}
betta.test <- betta(CB.hat, se.CB.hat, cbind(1, rep(c(0,1),each = n/2)))
betta.test.stat <- betta.test$table[2,1]/betta.test$table[2,2]
betta.est <- betta.test$table[2,1]
## agglomerate
X1 <- matrix(0, nrow = n, ncol = p/2)
for(i in 1:n){
for (j in 1:(p/2)){
X1[i,j] <- sum(X[i, tax.tab == j])
}
}
X1
X1 <- matrix(0, nrow = n, ncol = p/2)
for(i in 1:n){
for (j in 1:(p/2)){
X1[i,j] <- sum(X[i, tax.tab == j])
}
}
CB.hat.agg <- se.CB.hat.agg <- 1:n * 0
## get chao_bunge estimates
for (i in 1:n){
mb.samp.agg <- X1[i,]
freq.tab.agg <- apply(as.matrix(as.data.frame(table(mb.samp.agg))), 2, as.numeric)
freq.tab.agg <- freq.tab[freq.tab.agg[,1] != 0, ] ## omit unobserved entries
if (freq.tab.agg[1,1] != 1) freq.tab.agg <- rbind(c(1,0), freq.tab.agg)
rich <- chao_bunge(freq.tab.agg, cutoff = 10, output = F, answers = T)
CB.hat.agg[i] <- rich$est
se.CB.hat.agg[i] <- rich$seest
}
i
freq.tab.agg
## get chao_bunge estimates
for (i in 1:n){
mb.samp.agg <- X1[i,]
freq.tab.agg <- apply(as.matrix(as.data.frame(table(mb.samp.agg))), 2, as.numeric)
freq.tab.agg <- freq.tab.agg[freq.tab.agg[,1] != 0, ] ## omit unobserved entries
if (freq.tab.agg[1,1] != 1) freq.tab.agg <- rbind(c(1,0), freq.tab.agg)
rich <- chao_bunge(freq.tab.agg, cutoff = 10, output = F, answers = T)
CB.hat.agg[i] <- rich$est
se.CB.hat.agg[i] <- rich$seest
}
betta.agg.test <- betta(CB.hat.agg, se.CB.hat.agg, cbind(1, rep(c(0,1),each = n/2)))
betta.agg.test.stat <- betta.agg.test$table[2,1]/betta.agg.test$table[2,2]
betta.agg.est <- betta.agg.test$table[2,1]
betta.agg.est
betta.agg.test
CB.hat.agg
rep(1:n, 2)
group = rep(rep(c(0,1),each = n/2), 2)
group
cb.data.tab <- data.frame(CB.est = c(CB.hat, CB.hat.agg), CB.se = c(se.CB.hat, se.CB.hat.agg),
level = rep(0:1, each = n), sample.id = rep(1:n, 2),
group = rep(rep(c(0,1),each = n/2), 2))
?sort
cb.data.tab <- cb.data.tab[with(cb.data.tab, order(group, sample.id, level)),]
cb.data.tab
library(nlme)
library(clubSandwich)
?gls
?corSymm
?varIdent
?varFixed
global.model <- gls(CB.est ~ level*group, correlation = corSymm(form = ~1|sample.id),
weights = varFixed(~I(CB.se^2)))
cb.data.tab <- data.frame(CB.est = c(CB.hat, CB.hat.agg), CB.se = c(se.CB.hat, se.CB.hat.agg),
level = rep(0:1, each = n), sample.id = rep(1:n, 2),
group = rep(rep(c(0,1),each = n/2), 2))
cb.data.tab <- cb.data.tab[with(cb.data.tab, order(group, sample.id, level)),]
global.model <- gls(CB.est ~ level*group, correlation = corSymm(form = ~1|sample.id),
weights = varFixed(~I(CB.se^2)), data = cb.data.tab)
global.model
summary(global.model)
global.model <- gls(CB.est ~ as.factor(level)*group, correlation = corSymm(form = ~1|sample.id),
weights = varFixed(~I(CB.se^2)), data = cb.data.tab)
global.model
robust.se <- vcovCR(global.model, type = "CR0")
robust.se <- sqrt(diag(vcovCR(global.model, type = "CR0")))
robust.se
library(geepack)
groups <- expand.grid(1:3, 1:2)
data <- cbind(n = rep(100, 6),
x = rep(50, 6),
groups)
names(data) <- c("n", "x", "strata", "treatment")
strata = c(1:3, 1:3)
treatment = rep(1:2, 3)
nsubjects = rep(100, 6)
nresponders = rep(50, 6)
case = 2
nstrata <- length(unique(strata))
data <- data.frame(strata = strata, treatment = treatment,
nsubjects = nsubjects, nresponders = nresponders)
data
s <- sum(nresponders[treatment == case])
data.strata <- split(data, data$strata)
s
data.strata
x <- sapply(data.strata, function(tab) with(tab, nresponders[treatment == case])) ## responders in the treatment group
z <- sapply(data.strata, function(tab) with(tab, sum(nresponders))) ## total number of responders
n <- sapply(data.strata, function(tab) with(tab, sum(nsubjects))) ## total number of subjects in each stratum
m <- sapply(data.strata, function(tab) with(tab, nsubjects[treatment == case])) ## subjects in the treatment group
x
z
n
m
m_lower <- pmax(0, z-n+m)
m_upper <- pmin(z, m)
x_lower
m_lower
x_range <- vector(mode = "list", length = nstrata)
for(i in 1:nstrata){
x_range[[i]] <- m_lower[i]:m_upper[i]
}
x_range
x_prob <- x_range <- vector(mode = "list", length = nstrata)
for(i in 1:nstrata){
x_range[[i]] <- m_lower[i]:m_upper[i]
}
x_prob
z
nstrata
for(i in 1:nstrata){
x_prob[[i]] <- dhyper(x_range[[i]], m = m[i], n = n[i] - m[i], k = z[i])
}
x_prob
pv <- 0
x_grid <- expand.grid(x_range)
x_grid
head(x_grid)
x_prob_grid <- expand(x_prob)
x_prob_grid <- expand.grid(x_prob)
groups <- expand.grid(1:3, 1:2)
data <- cbind(n = rep(100, 6),
x = rep(50, 6),
groups)
names(data) <- c("n", "x", "strata", "treatment")
strata = c(1:3, 1:3)
treatment = rep(1:2, 3)
nsubjects = rep(100, 6)
nresponders = rep(50, 6)
case = 2
## case: specify which group is case
statifiedFisherTest <- function(strata, treatment, nsubjects, nresponders,
case, side = c("up", "lower", "both")){
nstrata <- length(unique(strata))
data <- data.frame(strata = strata, treatment = treatment,
nsubjects = nsubjects, nresponders = nresponders)
s <- sum(nresponders[treatment == case])
data.strata <- split(data, data$strata)
x <- sapply(data.strata, function(tab) with(tab, nresponders[treatment == case])) ## responders in the treatment group
z <- sapply(data.strata, function(tab) with(tab, sum(nresponders))) ## total number of responders
n <- sapply(data.strata, function(tab) with(tab, sum(nsubjects))) ## total number of subjects in each stratum
m <- sapply(data.strata, function(tab) with(tab, nsubjects[treatment == case])) ## subjects in the treatment group
m_lower <- pmax(0, z-n+m)
m_upper <- pmin(z, m)
x_prob <- x_range <- vector(mode = "list", length = nstrata)
for(i in 1:nstrata){
x_range[[i]] <- m_lower[i]:m_upper[i]
}
for(i in 1:nstrata){
x_prob[[i]] <- dhyper(x_range[[i]], m = m[i], n = n[i] - m[i], k = z[i])
}
pv <- 0
x_grid <- expand.grid(x_range)
x_prob_grid <- expand.grid(x_prob)
if (side == "up") {
for(i in 1:nrow(x_grid)){
if(sum(x_grid[i,]) >= s) pv <- pv + prod(x_prob_grid[i,])
}
} else if (side == "lower") {
for(i in 1:nrow(x_grid)){
if(sum(x_grid[i,]) <= s) pv <- pv + prod(x_prob_grid[i,])
}
} else if (side == "both") {
pv.up <- pv.lower <- 0
for(i in 1:nrow(x_grid)){
if(sum(x_grid[i,]) >= s) pv.up <- pv.up + prod(x_prob_grid[i,])
if(sum(x_grid[i,]) <= s) pv.lower <- pv.lower + prod(x_prob_grid[i,])
}
pv <- 2 * min(pv.up, pv.lower)
} else {
stop("side should be one of \"up\", \"lower\" or \"both\".")
}
return(pv)
}
system.time(pv.up <- statifiedFisherTest(strata, treatment, nsubjects, nresponders,
case = 2, side = "up"))
install.packages("profvis")
?profvis
library(profvis)
?profvis
a = 3
b = 4
save(b, c, file = "test.RData")
#!/bin/Rscript
## n: number of subjects in each group
## x: number of responders in each group
## toy example. Case: treatment = 2.
library(profvis)
groups <- expand.grid(1:3, 1:2)
data <- cbind(n = rep(100, 6),
x = rep(50, 6),
groups)
names(data) <- c("n", "x", "strata", "treatment")
strata = c(1:3, 1:3)
treatment = rep(1:2, 3)
nsubjects = rep(100, 6)
nresponders = rep(50, 6)
case = 2
## case: specify which group is case
profvis({
nstrata <- length(unique(strata))
data <- data.frame(strata = strata, treatment = treatment,
nsubjects = nsubjects, nresponders = nresponders)
s <- sum(nresponders[treatment == case])
data.strata <- split(data, data$strata)
x <- sapply(data.strata, function(tab) with(tab, nresponders[treatment == case])) ## responders in the treatment group
z <- sapply(data.strata, function(tab) with(tab, sum(nresponders))) ## total number of responders
n <- sapply(data.strata, function(tab) with(tab, sum(nsubjects))) ## total number of subjects in each stratum
m <- sapply(data.strata, function(tab) with(tab, nsubjects[treatment == case])) ## subjects in the treatment group
m_lower <- pmax(0, z-n+m)
m_upper <- pmin(z, m)
x_prob <- x_range <- vector(mode = "list", length = nstrata)
for(i in 1:nstrata){
x_range[[i]] <- m_lower[i]:m_upper[i]
}
for(i in 1:nstrata){
x_prob[[i]] <- dhyper(x_range[[i]], m = m[i], n = n[i] - m[i], k = z[i])
}
pv <- 0
x_grid <- expand.grid(x_range)
x_prob_grid <- expand.grid(x_prob)
pv.up <- pv.lower <- 0
for(i in 1:nrow(x_grid)){
if(sum(x_grid[i,]) >= s) pv.up <- pv.up + prod(x_prob_grid[i,])
if(sum(x_grid[i,]) <= s) pv.lower <- pv.lower + prod(x_prob_grid[i,])
}
pv <- 2 * min(pv.up, pv.lower)
save(pv, pv.up, pv.lower, file = "pv_prof.RData")
}, interval = 0.5)
#!/bin/Rscript
## n: number of subjects in each group
## x: number of responders in each group
## toy example. Case: treatment = 2.
library(profvis)
groups <- expand.grid(1:3, 1:2)
data <- cbind(n = rep(100, 6),
x = rep(50, 6),
groups)
names(data) <- c("n", "x", "strata", "treatment")
strata = c(1:3, 1:3)
treatment = rep(1:2, 3)
nsubjects = rep(100, 6)
nresponders = rep(50, 6)
case = 2
## case: specify which group is case
profvis({
nstrata <- length(unique(strata))
data <- data.frame(strata = strata, treatment = treatment,
nsubjects = nsubjects, nresponders = nresponders)
s <- sum(nresponders[treatment == case])
data.strata <- split(data, data$strata)
x <- sapply(data.strata, function(tab) with(tab, nresponders[treatment == case])) ## responders in the treatment group
z <- sapply(data.strata, function(tab) with(tab, sum(nresponders))) ## total number of responders
n <- sapply(data.strata, function(tab) with(tab, sum(nsubjects))) ## total number of subjects in each stratum
m <- sapply(data.strata, function(tab) with(tab, nsubjects[treatment == case])) ## subjects in the treatment group
m_lower <- pmax(0, z-n+m)
m_upper <- pmin(z, m)
x_prob <- x_range <- vector(mode = "list", length = nstrata)
for(i in 1:nstrata){
x_range[[i]] <- m_lower[i]:m_upper[i]
}
for(i in 1:nstrata){
x_prob[[i]] <- dhyper(x_range[[i]], m = m[i], n = n[i] - m[i], k = z[i])
}
pv <- 0
x_grid <- expand.grid(x_range)
x_prob_grid <- expand.grid(x_prob)
pv.up <- pv.lower <- 0
for(i in 1:nrow(x_grid)){
if(sum(x_grid[i,]) >= s) pv.up <- pv.up + prod(x_prob_grid[i,])
if(sum(x_grid[i,]) <= s) pv.lower <- pv.lower + prod(x_prob_grid[i,])
}
pv <- 2 * min(pv.up, pv.lower)
save(pv, pv.up, pv.lower, file = "pv_prof.RData")
}, interval = 0.5, prof_output = "exact_prof.Rata")
p <- c(50, 100, 200)
rare.ratio <- c(0.8, 0.4, 0.2)
abundant.weight <- c(10, 20, 40)
N <- 500
param.grid <- expand.grid(p, rare.ratio, abundant.weight)
p <- c(50, 100, 200)
rare.ratio <- c(0.8, 0.4, 0.2)
abundant.weight <- c(10, 20, 40)
N <- 500
param.grid <- expand.grid(p, rare.ratio, abundant.weight)
nrow(param.grid)
?step
setwd("//fs2-vip-nfs.nfs.biost.priv/students/qijunl2/Documents/UW/Ken/R_package/SFET/R")
setwd("//fs2-vip-nfs.nfs.biost.priv/students/qijunl2/Documents/UW/Ken/R_package/SFET/R")
list.files()
source("SFET.R")
SFET
